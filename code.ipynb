{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7lsBdkjRKyy",
        "outputId": "222a50c6-545c-494c-b16c-1dafd2ab7e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5-nAM37KKef"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import layers\n",
        "from sklearn.metrics import r2_score\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up dataframes\n",
        "# https://www.kaggle.com/datasets/christophercorrea/prisoners-and-crime-in-united-states\n",
        "JailDeaths = pd.read_csv(\"/content/drive/MyDrive/datasets/all_deaths.csv\", encoding='latin-1')\n",
        "JailStats = pd.read_csv(\"/content/drive/MyDrive/datasets/all_jails.csv\", encoding='latin-1')\n",
        "\n",
        "# https://www.kaggle.com/datasets/noriuk/us-education-datasets-unification-project\n",
        "Education_ByState = pd.read_csv(\"/content/drive/MyDrive/datasets/states_all.csv\", encoding='latin-1')\n",
        "\n",
        "# https://bjs.ojp.gov/library/publications/prisoners-2021-statistical-tables#:~:text=The%20U.S.%20prison%20population%20was,decrease%20from%202011%20(1%2C599%2C000)\n",
        "p21stt01 = pd.read_csv(\"/content/drive/MyDrive/datasets/p21stt01.csv\", encoding='latin-1')\n",
        "p21stat02 = pd.read_csv(\"/content/drive/MyDrive/datasets/p21stat02.csv\", encoding='latin-1')\n",
        "\n",
        "Education_ByState"
      ],
      "metadata": {
        "id": "91_oT0oeKVZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean up states_all_extended\n",
        "# set columns\n",
        "Education_ByState.columns = [\n",
        "    \"State Key\",\n",
        "    \"State\",\n",
        "    \"Year\",\n",
        "    \"Total Enrollment\",\n",
        "    \"Total Revenue\",\n",
        "    \"Federal Revenue\",\n",
        "    \"State Revenue\",\n",
        "    \"Local Revenue\",\n",
        "    \"Total Expenditure\",\n",
        "    \"Instruction Expenditure\",\n",
        "    \"Support Services Expenditure\",\n",
        "    \"Other Expenditure\",\n",
        "    \"Capital Outlay Expenditure\",\n",
        "    \"Total Enrollment (Pre-K)\",\n",
        "    \"Total Enrollment (K)\",\n",
        "    \"Total Enrollment (4)\",\n",
        "    \"Total Enrollment (8)\",\n",
        "    \"Total Enrollment (12)\",\n",
        "    \"Total Enrollment (1-8)\",\n",
        "    \"Total Enrollment (9-12)\",\n",
        "    \"Total Enrollment (ALL)\",\n",
        "    \"Average Math Score (4)\",\n",
        "    \"Average Math Score (8)\",\n",
        "    \"Average Reading Score (4)\",\n",
        "    \"Average Reading Score (8)\",\n",
        "]"
      ],
      "metadata": {
        "id": "_VNq2DXwKeJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Education Dataset Cleanup\n",
        "Education_ByStateCleaned = Education_ByState.drop(['State Key'], axis = 1)\n",
        "Education_ByStateCleaned = Education_ByStateCleaned[Education_ByStateCleaned['Year'] <= 2016]\n",
        "Education_ByStateCleaned = Education_ByStateCleaned[Education_ByStateCleaned['Year'] >= 1992]\n",
        "Education_ByStateCleaned = Education_ByStateCleaned[Education_ByStateCleaned['State'] != 'NATIONAL']\n",
        "Education_ByStateCleaned = Education_ByStateCleaned[Education_ByStateCleaned['State'] != 'DODEA']\n",
        "\n",
        "#Dropping rows that have NA values for Instruction Expenditure\n",
        "Education_ByStateCleaned = Education_ByStateCleaned.dropna(subset= ['Instruction Expenditure'])\n",
        "\n",
        "\n",
        "##Filtering Rows that have NAs for both enrollment estimates then filling one rows NAs with the other rows estimates. \n",
        "Education_ByStateCleaned[pd.notna(Education_ByStateCleaned['Total Enrollment']) | pd.notna(Education_ByStateCleaned['Total Enrollment (ALL)'])]\n",
        "Education_ByStateCleaned['Total Enrollment'] = Education_ByStateCleaned['Total Enrollment'].fillna(Education_ByStateCleaned['Total Enrollment (ALL)'])\n",
        "Education_ByStateCleaned.drop(['Total Enrollment (ALL)'], axis = 1)\n",
        "\n",
        "\n",
        "#Adding Expenditure Per Student To Clean DF\n",
        "Education_ByStateCleaned['Expenditure Per Student'] = Education_ByStateCleaned['Instruction Expenditure'] / Education_ByStateCleaned['Total Enrollment']\n",
        "\n",
        "Education_ByStateCleaned"
      ],
      "metadata": {
        "id": "jtTr_zC2Klgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Exploring The Data\n",
        "\n",
        "##Expenditure Per Student By State\n",
        "EducationExp = Education_ByStateCleaned\n",
        "\n",
        "#Selecting appropriate columns\n",
        "EducationExp = EducationExp[['State', 'Year', 'Expenditure Per Student', 'Average Math Score (4)']]"
      ],
      "metadata": {
        "id": "YZr0tf5ZKmMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Groupedby DF\n",
        "EducationExpGroupby = Education_ByStateCleaned.groupby('State').mean()\n",
        "EducationExpGroupby = EducationExpGroupby.reset_index().sort_values('Expenditure Per Student', ascending= False)\n",
        "EducationExpGroupby.index = EducationExpGroupby['State'] \n",
        "\n",
        "#Graphing Expenditure\n",
        "fig, ax = plt.subplots(figsize=(8,14))\n",
        "bars = plt.barh(EducationExpGroupby['State'],EducationExpGroupby['Expenditure Per Student'])\n",
        "plt.style.use('seaborn-v0_8-notebook')\n",
        "plt.ylabel(\"State\")\n",
        "ax.spines[['right','top','bottom']].set_visible(False)\n",
        "ax.xaxis.set_visible(False)\n",
        "ax.bar_label(bars)\n",
        "\n",
        "plt.title(\"Expenditure Per Student in Each State (1992-2016)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tATEmbwFKofY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graphing Math Scores\n",
        "EducationExpGroupby = EducationExpGroupby.sort_values('Average Math Score (4)', ascending= False)\n",
        "fig, ax = plt.subplots(figsize=(8,14))\n",
        "bars = plt.barh(EducationExpGroupby['State'],EducationExpGroupby['Average Math Score (4)'])\n",
        "plt.style.use('seaborn-v0_8-notebook')\n",
        "plt.ylabel(\"State\")\n",
        "ax.spines[['right','top','bottom']].set_visible(False)\n",
        "ax.xaxis.set_visible(False)\n",
        "ax.bar_label(bars)\n",
        "\n",
        "plt.title(\"Math Scores in Each State (1992-2016)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "grrlve2YKr9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploring Correlations Between Variables\n",
        "CorrelationEducation = Education_ByStateCleaned\n",
        "\n",
        "#Create Expenditure By Student\n",
        "# CorrelationEducation['Expenditure Per Student'] = CorrelationEducation['Instruction Expenditure'] / CorrelationEducation['Total Enrollment']\n",
        "CorrelationEducation = CorrelationEducation.drop(['State'], axis = 1)\n",
        "CorrelationEducation = CorrelationEducation[\n",
        "    pd.notna(CorrelationEducation['Average Math Score (4)']) & pd.notna(CorrelationEducation['Average Math Score (8)'])]\n",
        "\n",
        "\n",
        "# Scaling data\n",
        "Scaler = StandardScaler()\n",
        "Scaler.fit(CorrelationEducation)\n",
        "CorrelationEducation = pd.DataFrame(Scaler.transform(CorrelationEducation), \n",
        "        columns= CorrelationEducation.columns)\n",
        "\n",
        "#Creating Correlation Matrix\n",
        "corr = CorrelationEducation.dropna().corr()\n",
        "plt.figure(num=None, figsize=(8, 8), dpi=80, facecolor='w', edgecolor='k')\n",
        "corrMat = plt.matshow(corr, fignum = 1)\n",
        "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
        "plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "plt.gca().xaxis.tick_bottom()\n",
        "plt.colorbar(corrMat)\n",
        "plt.title(f'Correlation Matrix', fontsize=15)\n",
        "plt.show()\n",
        "\n",
        "#Selecting Certain Correlations From The Matrix\n",
        "CorrelationEducation['Capital Outlay Expenditure'].corr(CorrelationEducation['Average Reading Score (8)'])"
      ],
      "metadata": {
        "id": "OWdWhGqvKvHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Linear Regression Models\n",
        "import math\n",
        "MSEList = []\n",
        "ADJRSQUARED = []\n",
        "\n",
        "#Model1\n",
        "Model1Data = CorrelationEducation[['Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Year']]\n",
        "Model1Data = Model1Data[pd.notna(Model1Data['Average Math Score (4)']) & pd.notna(Model1Data['Average Math Score (8)']) \n",
        "                                        & pd.notna(Model1Data['Expenditure Per Student']) & pd.notna(Model1Data['Year'])]\n",
        "TestingFloor = math.floor(len(Model1Data) * .8)\n",
        "Model1DataTraining = Model1Data[[ 'Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Year']].iloc[0:TestingFloor]\n",
        "Model1DataTesting = Model1Data[['Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Year']].iloc[TestingFloor:]\n",
        "\n",
        "\n",
        "model = LinearRegression(fit_intercept= True)\n",
        "XTraining = Model1DataTraining[['Average Math Score (4)', 'Expenditure Per Student', 'Year']]\n",
        "YTraining = Model1DataTraining['Average Math Score (8)']\n",
        "XTesting = Model1DataTesting[['Average Math Score (4)', 'Expenditure Per Student', 'Year']]\n",
        "YTesting = Model1DataTesting['Average Math Score (8)']\n",
        "model.fit(XTraining, YTraining)\n",
        "ModelPredictions = model.predict(XTesting)\n",
        "MSEList.append(metrics.mean_squared_error(ModelPredictions, YTesting))\n",
        "ADJRSQUARED.append((1-(1-r2_score(YTesting, ModelPredictions))*((len(XTesting)-1)/(len(XTesting)-len(XTesting.columns)-1))))\n",
        "\n",
        "\n",
        "\n",
        "#Model2\n",
        "Model2Data = CorrelationEducation[['Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Year', 'Average Reading Score (4)']]\n",
        "Model2Data = Model2Data[pd.notna(Model2Data['Average Math Score (4)']) & pd.notna(Model2Data['Average Math Score (8)']) \n",
        "                                        & pd.notna(Model2Data['Expenditure Per Student']) & pd.notna(Model2Data['Year'])\n",
        "                                        & pd.notna(Model2Data['Average Reading Score (4)'])]\n",
        "TestingFloor = math.floor(len(Model2Data) * .8)\n",
        "Model2DataTraining = Model2Data[[ 'Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Year', 'Average Reading Score (4)']].iloc[0:TestingFloor]\n",
        "Model2DataTesting = Model2Data[['Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Year', 'Average Reading Score (4)']].iloc[TestingFloor:]\n",
        "\n",
        "model = LinearRegression(fit_intercept= True)\n",
        "XTraining = Model2DataTraining[['Average Math Score (4)', 'Expenditure Per Student', 'Year', 'Average Reading Score (4)']]\n",
        "YTraining = Model2DataTraining['Average Math Score (8)']\n",
        "XTesting = Model2DataTesting[['Average Math Score (4)', 'Expenditure Per Student', 'Year', 'Average Reading Score (4)']]\n",
        "YTesting = Model2DataTesting['Average Math Score (8)']\n",
        "model.fit(XTraining, YTraining)\n",
        "ModelPredictions = model.predict(XTesting)\n",
        "MSEList.append(metrics.mean_squared_error(ModelPredictions, YTesting))\n",
        "ADJRSQUARED.append((1-(1-r2_score(YTesting, ModelPredictions))*((len(XTesting)-1)/(len(XTesting)-len(XTesting.columns)-1))))\n",
        "#Model 3 (Final Model)\n",
        "\n",
        "Model3Data = CorrelationEducation[['Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Average Reading Score (4)', 'Average Reading Score (8)']]\n",
        "Model3Data = Model3Data[pd.notna(Model3Data['Average Math Score (4)']) & pd.notna(Model3Data['Average Math Score (8)']) \n",
        "                                        & pd.notna(Model3Data['Expenditure Per Student']) & pd.notna(Model3Data['Average Reading Score (4)']) & pd.notna(Model3Data['Average Reading Score (8)'])]\n",
        "Model4DataTraining = Model3Data[[ 'Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Average Reading Score (4)', 'Average Reading Score (8)']].iloc[0:285]\n",
        "Model4DataTesting = Model3Data[['Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Average Reading Score (4)', 'Average Reading Score (8)']].iloc[285:]\n",
        "\n",
        "model = LinearRegression(fit_intercept= True)\n",
        "XTraining = Model4DataTraining[['Average Math Score (4)', 'Expenditure Per Student', 'Average Reading Score (4)', 'Average Reading Score (8)']]\n",
        "YTraining = Model4DataTraining['Average Math Score (8)']\n",
        "XTesting = Model4DataTesting[['Average Math Score (4)', 'Expenditure Per Student', 'Average Reading Score (4)', 'Average Reading Score (8)']]\n",
        "YTesting = Model4DataTesting['Average Math Score (8)']\n",
        "model.fit(XTraining, YTraining)\n",
        "ModelPredictions = model.predict(XTesting)\n",
        "MSEList.append(metrics.mean_squared_error(ModelPredictions, YTesting))\n",
        "ADJRSQUARED.append((1-(1-r2_score(YTesting, ModelPredictions))*((len(XTesting)-1)/(len(XTesting)-len(XTesting.columns)-1))))\n",
        "print(ADJRSQUARED)"
      ],
      "metadata": {
        "id": "8gv-adDfKv1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(YTesting,ModelPredictions, color='purple', label='Total Enrollment',s=15)\n",
        "\n",
        "# Create the regression line using the calculated coefficients\n",
        "regression_line = YTesting \n",
        "\n",
        "plt.plot(YTesting, regression_line, color='red', label='Regression Line')\n",
        "\n",
        "for x, y, ln in zip(YTesting, ModelPredictions, regression_line):\n",
        "    plt.plot([x, x], [y, ln], color='black', linestyle='--', linewidth=0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jgqWM17tPJQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Polynomial Model\n",
        "PolynomialModelData = CorrelationEducation[['Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Average Reading Score (4)', 'Average Reading Score (8)']]\n",
        "PolynomialModelData = PolynomialModelData[pd.notna(PolynomialModelData['Average Math Score (4)']) & pd.notna(PolynomialModelData['Average Math Score (8)']) \n",
        "                                        & pd.notna(PolynomialModelData['Expenditure Per Student']) & pd.notna(PolynomialModelData['Average Reading Score (4)']) & pd.notna(PolynomialModelData['Average Reading Score (8)'])]\n",
        "TestingFloor = math.floor(len(PolynomialModelData) * .8)\n",
        "PolynomialModelDataTraining = PolynomialModelData[[ 'Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Average Reading Score (4)', 'Average Reading Score (8)']].iloc[0:TestingFloor]\n",
        "PolynomialModelDataTesting = PolynomialModelData[['Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Average Reading Score (4)', 'Average Reading Score (8)']].iloc[TestingFloor:]\n",
        "\n",
        "PolyModel1 = make_pipeline(PolynomialFeatures(2, include_bias = False),LinearRegression())\n",
        "XTraining = PolynomialModelDataTraining[['Average Math Score (4)', 'Expenditure Per Student', 'Average Reading Score (4)', 'Average Reading Score (8)']]\n",
        "YTraining = PolynomialModelDataTraining['Average Math Score (8)']\n",
        "PolyModel1.fit(XTraining, YTraining)\n",
        "XTesting = PolynomialModelDataTesting[['Average Math Score (4)', 'Expenditure Per Student', 'Average Reading Score (4)', 'Average Reading Score (8)']]\n",
        "YTesting = PolynomialModelDataTesting['Average Math Score (8)']\n",
        "ModelPredictions = PolyModel1.predict(XTesting)\n",
        "ADJRSQUARED.append((1-(1-r2_score(YTesting, ModelPredictions))*((len(XTesting)-1)/(len(XTesting)-len(XTesting.columns)-1))))\n",
        "MSEList.append(metrics.mean_squared_error(ModelPredictions, YTesting))\n",
        "\n",
        "#Basis 3\n",
        "PolyModel2 = make_pipeline(PolynomialFeatures(3), LinearRegression())\n",
        "PolyModel2.fit(XTraining, YTraining)\n",
        "ModelPredictions = PolyModel2.predict(XTesting)\n",
        "ADJRSQUARED.append((1-(1-r2_score(YTesting, ModelPredictions))*((len(XTesting)-1)/(len(XTesting)-len(XTesting.columns)-1))))\n",
        "MSEList.append(metrics.mean_squared_error(ModelPredictions, YTesting))\n",
        "print(ADJRSQUARED)"
      ],
      "metadata": {
        "id": "u7kiZFOZKy0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring why a linear regression outperforms polynomial regression.\n",
        "\n",
        "\n",
        "# Filter Proper Rows\n",
        "PMEXPFILTERED = Education_ByStateCleaned[['Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Year', 'Average Reading Score (4)', 'Average Reading Score (8)']]\n",
        "PMEXPFILTERED = PMEXPFILTERED[pd.notna(PMEXPFILTERED['Average Math Score (4)']) & pd.notna(PMEXPFILTERED['Average Math Score (8)']) \n",
        "                                        & pd.notna(PMEXPFILTERED['Expenditure Per Student']) & pd.notna(PMEXPFILTERED['Year'])\n",
        "                                        & pd.notna(PMEXPFILTERED['Average Reading Score (4)']) & pd.notna(PMEXPFILTERED['Average Reading Score (8)'])]\n",
        "fig, axs = plt.subplots(2, 2)\n",
        "plt.sca(axs[0,0])\n",
        "plt.title('Average Math Score (4)')\n",
        "plt.sca(axs[0,1])\n",
        "plt.title('Average Reading Score (4)')\n",
        "plt.suptitle('Variable Relationships With Average Math Score (8)')\n",
        "\n",
        "plt.sca(axs[1,0])\n",
        "plt.title('Expenditure Per Student')\n",
        "plt.sca(axs[1,1])\n",
        "plt.title('Average Reading Score (8)')\n",
        "# Adjust vertical_spacing = 0.5 * axes_height\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.scatter(PMEXPFILTERED['Average Math Score (4)'], PMEXPFILTERED['Average Math Score (8)'])\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.scatter(PMEXPFILTERED['Average Reading Score (4)'], PMEXPFILTERED['Average Math Score (8)'])\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.scatter(PMEXPFILTERED['Expenditure Per Student'], PMEXPFILTERED['Average Math Score (8)'])\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.scatter(PMEXPFILTERED['Average Reading Score (8)'], PMEXPFILTERED['Average Math Score (8)'])"
      ],
      "metadata": {
        "id": "qAqGt5rUK1J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Neural Network Regression\n",
        "NNData = CorrelationEducation[['Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Year', 'Average Reading Score (4)', 'Average Reading Score (8)']]\n",
        "NNData = NNData[pd.notna(NNData['Average Math Score (4)']) & pd.notna(NNData['Average Math Score (8)']) \n",
        "                                        & pd.notna(NNData['Expenditure Per Student']) & pd.notna(NNData['Year'])\n",
        "                                        & pd.notna(NNData['Average Reading Score (4)']) & pd.notna(NNData['Average Reading Score (8)'])]\n",
        "TestingFloor = math.floor(len(NNData) * .8)\n",
        "NNDataDataTraining = NNData[[ 'Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Year', 'Average Reading Score (4)', 'Average Reading Score (8)']].iloc[0:TestingFloor]\n",
        "NNDataDataTesting = NNData[['Average Math Score (4)', 'Expenditure Per Student', 'Average Math Score (8)', 'Year', 'Average Reading Score (4)', 'Average Reading Score (8)']].iloc[TestingFloor:]\n",
        "\n",
        "XTraining = NNDataDataTraining[['Average Math Score (4)', 'Expenditure Per Student', 'Year', 'Average Reading Score (4)', 'Average Reading Score (8)']]\n",
        "YTraining = NNDataDataTraining['Average Math Score (8)']\n",
        "\n",
        "XTesting = NNDataDataTesting[['Average Math Score (4)', 'Expenditure Per Student', 'Year', 'Average Reading Score (4)', 'Average Reading Score (8)']]\n",
        "YTesting = NNDataDataTesting['Average Math Score (8)']\n",
        "\n",
        "\n",
        "#Filter Proper Rows\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(5,activation='relu', \n",
        "\t\t\t\t\tinput_shape=(5,)))\n",
        "model.add(layers.Dense(4,activation='relu'))\n",
        "model.add(layers.Dense(4,activation='relu'))\n",
        "model.add(layers.Dense(4,activation='relu'))\n",
        "model.add(layers.Dense(1, activation='linear'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mean_squared_error'])\n",
        "model.fit(XTraining,YTraining, epochs = 50)\n",
        "results = model.evaluate(XTesting, YTesting)\n",
        "\n",
        "\n",
        "MSEList.append(results[1])\n",
        "print(MSEList[-1])"
      ],
      "metadata": {
        "id": "atbqCFe2K3Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graphing MSE Per Model\n",
        "ModelNumber = ['L1',\"L2\",\"L3\",\"P2\",\"P3\",\"NN\"]\n",
        "plt.bar(ModelNumber,MSEList)\n",
        "plt.title(\"Comparing Respective Mean Squared Errors\")\n",
        "plt.xlabel(\"Model Number\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.ylim(0, .25)"
      ],
      "metadata": {
        "id": "hIBMERAkK6SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graphing Adjusted R Squared Per Model\n",
        "ModelNumber = ['L1',\"L2\",\"L3\",\"P2\",\"P3\"]\n",
        "plt.bar(ModelNumber,ADJRSQUARED)\n",
        "plt.title(\"Comparing Respective Adjusted R Squared\")\n",
        "plt.xlabel(\"Model Number\")\n",
        "plt.ylabel(\"Adjusted R Squared\")\n",
        "plt.ylim(0, 1)"
      ],
      "metadata": {
        "id": "3l_K9gwEK8lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Jail Data\n",
        "# https://www.kaggle.com/datasets/christophercorrea/prisoners-and-crime-in-united-states?select=crime_and_incarceration_by_state.csv\n",
        "crimesAndIncarcerationsByState = pd.read_csv(\"/content/drive/MyDrive/datasets/crime_and_incarceration_by_state.csv\", encoding='latin-1')\n",
        "prisonCustodyByState = pd.read_csv(\"/content/drive/MyDrive/datasets/prison_custody_by_state.csv\", encoding='latin-1')\n",
        "crimeTotalsByState = pd.read_csv(\"/content/drive/MyDrive/datasets/ucr_by_state.csv\", encoding='latin-1')"
      ],
      "metadata": {
        "id": "7wJl0V_bK_0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#crimetotal cleanup\n",
        "crimeTotalsByStateCleaned = crimeTotalsByState.drop([\"Unnamed: 15\", \"Unnamed: 16\", \"Unnamed: 17\", \"Unnamed: 18\", \"Unnamed: 19\", \"Unnamed: 20\", \"crime_reporting_change\", \"crimes_estimated\", \"rape_legacy\", 'rape_revised'], axis=1)\n",
        "crimeTotalsByStateCleaned = crimeTotalsByStateCleaned.drop(range(869, 948)).reset_index(drop=True)\n",
        "crimeTotalsByStateCleaned = crimeTotalsByStateCleaned.rename(columns={\"ï»¿jurisdiction\": \"State\", \"year\": \"Year\"})\n",
        "crimeTotalsByStateCleaned[\"Year\"] = crimeTotalsByStateCleaned[\"Year\"].astype(int)\n",
        "crimeTotalsByStateCleaned = crimeTotalsByStateCleaned[crimeTotalsByStateCleaned['Year'] >= 2001]\n",
        "crimeTotalsByStateCleaned = crimeTotalsByStateCleaned[crimeTotalsByStateCleaned['Year'] <= 2016]\n",
        "\n",
        "crimeTotalsByStateCleaned['State'] = crimeTotalsByStateCleaned['State'].str.upper()\n",
        "\n",
        "#Cleaning all the columns with commas and converting to int\n",
        "crimeTotalsByStateCleaned['state_population'] = crimeTotalsByStateCleaned['state_population'].str.replace(',', '').astype(int)\n",
        "crimeTotalsByStateCleaned['violent_crime_total'] = crimeTotalsByStateCleaned['violent_crime_total'].str.replace(',', '').astype(int)\n",
        "crimeTotalsByStateCleaned['murder_manslaughter'] = crimeTotalsByStateCleaned['murder_manslaughter'].str.replace(',', '').astype(int)\n",
        "# crimeTotalsByStateCleaned['rape_legacy'] = crimeTotalsByStateCleaned['rape_legacy'].str.replace(',', '').astype(int)\n",
        "# crimeTotalsByStateCleaned['rape_revised'] = crimeTotalsByStateCleaned['rape_revised'].str.replace(',', '').astype(int)\n",
        "crimeTotalsByStateCleaned['robbery'] = crimeTotalsByStateCleaned['robbery'].str.replace(',', '').astype(int)\n",
        "crimeTotalsByStateCleaned['agg_assault'] = crimeTotalsByStateCleaned['agg_assault'].str.replace(',', '').astype(int)\n",
        "crimeTotalsByStateCleaned['property_crime_total'] = crimeTotalsByStateCleaned['property_crime_total'].str.replace(',', '').astype(int)\n",
        "crimeTotalsByStateCleaned['burglary'] = crimeTotalsByStateCleaned['burglary'].str.replace(',', '').astype(int)\n",
        "crimeTotalsByStateCleaned['larceny'] = crimeTotalsByStateCleaned['larceny'].str.replace(',', '').astype(int)\n",
        "crimeTotalsByStateCleaned['vehicle_theft'] = crimeTotalsByStateCleaned['vehicle_theft'].str.replace(',', '').astype(int)\n",
        "\n",
        "crimeTotalsByStateCleaned = crimeTotalsByStateCleaned.rename(columns={\"state_population\": \"State Population\", \n",
        "                                                                      \"violent_crime_total\": \"Violent Total Crime\",\n",
        "                                                                      \"murder_manslaughter\": \"Murder\",\n",
        "                                                                      \"rape_revised\": \"Rape(Revised)\",\n",
        "                                                                      \"robbery\": \"Robbery\",\n",
        "                                                                      \"agg_assault\": \"Agg Assault\",\n",
        "                                                                      \"property_crime_total\": \"Property Crime Total\",\n",
        "                                                                      \"burglary\": \"Burglary\",\n",
        "                                                                      \"larceny\": \"Larceny\",\n",
        "                                                                      \"vehicle_theft\": \"Vehicle Theft\"})"
      ],
      "metadata": {
        "id": "c7Cb-wrHLAZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merging DFs\n",
        "CrimeEducationMerged = pd.merge(Education_ByStateCleaned, crimeTotalsByStateCleaned, on=['State', 'Year'])\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "display(CrimeEducationMerged)"
      ],
      "metadata": {
        "id": "YePioXz2LCrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Exploring The Jail Data\n",
        "\n",
        "##Support Expenditure Per Student By State\n",
        "EducationSupportExp = CrimeEducationMerged\n",
        "\n",
        "#Selecting appropriate columns\n",
        "EducationSupportExp = EducationSupportExp[['State', 'Year', 'Total Enrollment', 'Support Services Expenditure','Vehicle Theft']]\n",
        "\n",
        "#Create Expenditure By Student\n",
        "EducationSupportExp['Support Per Student'] = EducationSupportExp['Support Services Expenditure'] / EducationSupportExp['Total Enrollment']\n",
        "EducationSupportExpGroupby = EducationSupportExp.groupby('State').mean()\n",
        "EducationSupportExpGroupby = EducationSupportExpGroupby.reset_index().sort_values('Support Per Student', ascending= False)\n",
        "\n",
        "EducationSupportExpGroupby.index = EducationSupportExpGroupby['State'] "
      ],
      "metadata": {
        "id": "z7dBdrbcLETy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Groupedby DF\n",
        "EducationSupportExpGroupby = EducationSupportExp.groupby('State').mean()\n",
        "EducationSupportExpGroupby = EducationSupportExpGroupby.reset_index().sort_values('Support Per Student', ascending= False)\n",
        "EducationSupportExpGroupby.index = EducationSupportExpGroupby['State'] \n",
        "\n",
        "#Graphing Support\n",
        "fig, ax = plt.subplots(figsize=(8,14))\n",
        "bars = plt.barh(EducationSupportExpGroupby['State'],EducationSupportExpGroupby['Support Per Student'])\n",
        "plt.style.use('seaborn-v0_8-notebook')\n",
        "plt.ylabel(\"State\")\n",
        "ax.spines[['right','top','bottom']].set_visible(False)\n",
        "ax.xaxis.set_visible(False)\n",
        "ax.bar_label(bars)\n",
        "\n",
        "plt.title(\"Support Per Student in Each State (2001-2016)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rLsjz4aXLGFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EducationSupportExpGroupby = EducationSupportExp.groupby('State').mean()\n",
        "EducationSupportExpGroupby['Theft Per Person'] = EducationSupportExpGroupby['Vehicle Theft']/EducationSupportExpGroupby['Total Enrollment']\n",
        "EducationSupportExpGroupby = EducationSupportExpGroupby.reset_index().sort_values('Theft Per Person', ascending= False)\n",
        "fig, ax = plt.subplots(figsize=(6,10))\n",
        "bars = plt.barh(EducationSupportExpGroupby['State'],EducationSupportExpGroupby['Theft Per Person'])\n",
        "plt.style.use('seaborn-v0_8-notebook')\n",
        "plt.ylabel(\"State\")\n",
        "ax.spines[['right','top','bottom']].set_visible(False)\n",
        "ax.xaxis.set_visible(False)\n",
        "ax.bar_label(bars)\n",
        "\n",
        "plt.title(\"Standardized Vehicle Thefts in Each State (2001-2016)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o_4OhZVuLH3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploring Correlations Between Variables\n",
        "CorrelationCrime = CrimeEducationMerged\n",
        "\n",
        "#Create Expenditure By Student\n",
        "CorrelationCrime = CorrelationCrime.drop(['State'], axis = 1)\n",
        "# CorrelationCrime = CorrelationCrime[pd.notna(CorrelationEducation['Average Math Score (4)']) & pd.notna(CorrelationEducation['Average Math Score (8)'])]\n",
        "\n",
        "\n",
        "# Scaling data\n",
        "Scaler = StandardScaler()\n",
        "Scaler.fit(CorrelationCrime)\n",
        "CorrelationCrime = pd.DataFrame(Scaler.transform(CorrelationCrime), \n",
        "        columns= CorrelationCrime.columns)\n",
        "\n",
        "#Creating Correlation Matrix\n",
        "corr = CorrelationCrime.dropna().corr()\n",
        "plt.figure(num=None, figsize=(8, 8), dpi=80, facecolor='w', edgecolor='k')\n",
        "corrMat = plt.matshow(corr, fignum = 1)\n",
        "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
        "plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "plt.gca().xaxis.tick_bottom()\n",
        "plt.colorbar(corrMat)\n",
        "plt.title(f'Correlation Matrix', fontsize=15)\n",
        "plt.show()\n",
        "\n",
        "#Selecting Certain Correlations From The Matrix\n",
        "CorrelationCrime['Support Services Expenditure'].corr(CorrelationCrime['Vehicle Theft'])"
      ],
      "metadata": {
        "id": "NvSNGsTwLLmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting Vehicle Theft\n",
        "\n",
        "#Creating ADJ R2 List\n",
        "ADJRSQUAREDJAIL= []\n",
        "\n",
        "#MSE List\n",
        "MSEListJail = []\n",
        "\n",
        "#Model 1\n",
        "Model1Data = CrimeEducationMerged[['Violent Total Crime', 'Support Services Expenditure', 'Vehicle Theft']]\n",
        "Model1Data = Model1Data[pd.notna(Model1Data['Violent Total Crime']) & pd.notna(Model1Data['Support Services Expenditure']) & \n",
        "                        pd.notna(Model1Data['Vehicle Theft'])]\n",
        "\n",
        "TestingFloor = math.floor(len(Model1Data) * .8)\n",
        "Model1DataTraining = Model1Data.iloc[0:TestingFloor]\n",
        "Model1DataTesting = Model1Data.iloc[TestingFloor:]\n",
        "\n",
        "\n",
        "model = LinearRegression(fit_intercept= True)\n",
        "XTraining = Model1DataTraining[['Violent Total Crime', 'Support Services Expenditure']]\n",
        "YTraining = Model1DataTraining['Vehicle Theft']\n",
        "XTesting = Model1DataTesting[['Violent Total Crime', 'Support Services Expenditure']]\n",
        "\n",
        "print(XTesting)\n",
        "print(len(XTesting))\n",
        "\n",
        "YTesting = Model1DataTesting['Vehicle Theft']\n",
        "model.fit(XTraining, YTraining)\n",
        "ModelPredictions = model.predict(XTesting)\n",
        "MSEListJail.append(metrics.mean_squared_error(ModelPredictions, YTesting))\n",
        "ADJRSQUAREDJAIL.append((1-(1-r2_score(YTesting, ModelPredictions))*((len(XTesting)-1)/(len(XTesting)-len(XTesting.columns)-1))))\n",
        "\n",
        "#Model2 \n",
        "Model2Data = CrimeEducationMerged[['Violent Total Crime', 'Support Services Expenditure', 'Vehicle Theft', 'State Revenue']]\n",
        "Model2Data = Model2Data[pd.notna(Model2Data['Violent Total Crime']) & pd.notna(Model2Data['Support Services Expenditure']) & \n",
        "                        pd.notna(Model2Data['Vehicle Theft']) & pd.notna(Model2Data['State Revenue'])]\n",
        "\n",
        "TestingFloor = math.floor(len(Model2Data) * .8)\n",
        "Model2DataTraining = Model2Data.iloc[0:TestingFloor]\n",
        "Model2DataTesting = Model2Data.iloc[TestingFloor:]\n",
        "\n",
        "\n",
        "model = LinearRegression(fit_intercept= True)\n",
        "XTraining = Model2DataTraining[['Violent Total Crime', 'Support Services Expenditure', 'State Revenue']]\n",
        "YTraining = Model2DataTraining['Vehicle Theft']\n",
        "XTesting = Model2DataTesting[['Violent Total Crime', 'Support Services Expenditure', 'State Revenue']]\n",
        "YTesting = Model2DataTesting['Vehicle Theft']\n",
        "model.fit(XTraining, YTraining)\n",
        "ModelPredictions = model.predict(XTesting)\n",
        "MSEListJail.append(metrics.mean_squared_error(ModelPredictions, YTesting))\n",
        "ADJRSQUAREDJAIL.append((1-(1-r2_score(YTesting, ModelPredictions))*((len(XTesting)-1)/(len(XTesting)-len(XTesting.columns)-1))))\n",
        "\n",
        "#Polynomial Model\n",
        "PolyModel = CrimeEducationMerged[['Violent Total Crime', 'Support Services Expenditure', 'Vehicle Theft', 'State Revenue']]\n",
        "PolyModel = PolyModel[pd.notna(PolyModel['Violent Total Crime']) & pd.notna(PolyModel['Support Services Expenditure']) & \n",
        "                        pd.notna(PolyModel['Vehicle Theft']) & pd.notna(PolyModel['State Revenue'])]\n",
        "\n",
        "TestingFloor = math.floor(len(PolyModel) * .8)\n",
        "PolyModelTraining = PolyModel.iloc[0:TestingFloor]\n",
        "PolyModelTesting = PolyModel.iloc[TestingFloor:]\n",
        "\n",
        "\n",
        "model = make_pipeline(PolynomialFeatures(2), LinearRegression(fit_intercept= True))\n",
        "XTraining = PolyModelTraining[['Violent Total Crime', 'Support Services Expenditure', 'State Revenue']]\n",
        "YTraining = PolyModelTraining['Vehicle Theft']\n",
        "XTesting = PolyModelTesting[['Violent Total Crime', 'Support Services Expenditure', 'State Revenue']]\n",
        "YTesting = PolyModelTesting['Vehicle Theft']\n",
        "model.fit(XTraining, YTraining)\n",
        "ModelPredictions = model.predict(XTesting)\n",
        "MSEListJail.append(metrics.mean_squared_error(ModelPredictions, YTesting))\n",
        "ADJRSQUAREDJAIL.append((1-(1-r2_score(YTesting, ModelPredictions))*((len(XTesting)-1)/(len(XTesting)-len(XTesting.columns)-1))))\n",
        "\n",
        "#EducationModel\n",
        "Model2Data = CrimeEducationMerged[['Support Services Expenditure', 'Vehicle Theft', 'State Revenue', 'Total Enrollment']]\n",
        "Model2Data = Model2Data[pd.notna(Model2Data['Total Enrollment']) & pd.notna(Model2Data['Support Services Expenditure']) & \n",
        "                        pd.notna(Model2Data['Vehicle Theft']) & pd.notna(Model2Data['State Revenue'])]\n",
        "\n",
        "TestingFloor = math.floor(len(Model2Data) * .8)\n",
        "Model2DataTraining = Model2Data.iloc[0:TestingFloor]\n",
        "Model2DataTesting = Model2Data.iloc[TestingFloor:]\n",
        "\n",
        "\n",
        "model = LinearRegression(fit_intercept= True)\n",
        "XTraining = Model2DataTraining[['Total Enrollment', 'Support Services Expenditure', 'State Revenue']]\n",
        "YTraining = Model2DataTraining['Vehicle Theft']\n",
        "XTesting = Model2DataTesting[['Total Enrollment', 'Support Services Expenditure', 'State Revenue']]\n",
        "YTesting = Model2DataTesting['Vehicle Theft']\n",
        "model.fit(XTraining, YTraining)\n",
        "ModelPredictions = model.predict(XTesting)\n",
        "print(metrics.r2_score(ModelPredictions, YTesting))\n",
        "MSEListJail.append(metrics.mean_squared_error(ModelPredictions, YTesting))\n",
        "ADJRSQUAREDJAIL.append((1-(1-r2_score(YTesting, ModelPredictions))*((len(XTesting)-1)/(len(XTesting)-len(XTesting.columns)-1))))\n"
      ],
      "metadata": {
        "id": "5oclwoixLONB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(YTesting,ModelPredictions, color='purple', label='Total Enrollment',s=15)\n",
        "\n",
        "# Create the regression line using the calculated coefficients\n",
        "regression_line = YTesting \n",
        "\n",
        "plt.plot(YTesting, regression_line, color='red', label='Regression Line')\n",
        "\n",
        "for x, y, ln in zip(YTesting, ModelPredictions, regression_line):\n",
        "    plt.plot([x, x], [y, ln], color='black', linestyle='--', linewidth=0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IpAceYWcNVZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ModelNumber = [\"1\",\"2\",\"3\",\"4\"]\n",
        "plt.grid(True, zorder = 0, color = \"grey\", linewidth = \"1\", linestyle = \"--\")\n",
        "plt.bar(ModelNumber,ADJRSQUAREDJAIL,zorder=3)\n",
        "plt.title(\"Adj R^2 By Model\")\n",
        "plt.xlabel(\"Model Number\")\n",
        "plt.ylabel(\"Adj R^2 Value\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8qxus3uyNZ6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ModelNumber = [\"1\",\"2\",\"3\",\"4\"]\n",
        "plt.grid(True, zorder = 0, color = \"grey\", linewidth = \"1\", linestyle = \"--\")\n",
        "plt.bar(ModelNumber,MSEListJail,zorder=3)\n",
        "plt.title(\"MSE By Model\")\n",
        "plt.xlabel(\"Model Number\")\n",
        "plt.ylabel(\"MSE Value\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d8piIaIWNkhR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}